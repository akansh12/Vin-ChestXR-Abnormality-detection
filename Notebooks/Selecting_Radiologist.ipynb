{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6be7ca",
   "metadata": {},
   "source": [
    "### Selcting the Radiologist\n",
    "\n",
    "- Randomly Select one\n",
    "- Agreement Between two, remove the third\n",
    "- Agreement of three\n",
    "- All \n",
    "- One radiologist in one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e73ab403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8e0317a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "from torchvision import transforms, models, datasets\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "import cv2\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "95e194b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csv = {'train': \"/scratch/scratch6/akansh12/DeepEXrays/physionet.org/files/vindr-cxr/1.0.0/annotations/image_labels_train.csv\",\n",
    "             'test': \"/scratch/scratch6/akansh12/DeepEXrays/physionet.org/files/vindr-cxr/1.0.0/annotations/image_labels_test.csv\"\n",
    "             }\n",
    "\n",
    "data_dir = {'train': \"/scratch/scratch6/akansh12/DeepEXrays/data/data_1024/train/\",\n",
    "           'test': \"/scratch/scratch6/akansh12/DeepEXrays/data/data_1024/test/\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "75d6c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_labels = ['Pleural effusion', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other diseases', 'No finding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3ebc1b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "selec_radio = ['rand_one', 'agree_two', 'agree_three', 'radio_per_epoch', 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8045f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "class Vin_big_dataset(Dataset):\n",
    "    def __init__(self, image_loc, label_loc, transforms, data_type, selec_radio, radio_id = None):\n",
    "        global_labels = ['Pleural effusion', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other diseases', 'No finding']\n",
    "        \n",
    "        if data_type == 'train':\n",
    "            label_df = pd.read_csv(label_loc)\n",
    "            if selec_radio == 'rand_one':\n",
    "                label_df['labels'] = label_df['image_id']\n",
    "                label_df.set_index(\"labels\", inplace = True)\n",
    "                filenames = np.unique(label_df.index.values).tolist()\n",
    "                self.full_filenames = [os.path.join(image_loc, i +'.png') for i in filenames]\n",
    "                self.labels = []\n",
    "                for i in tqdm(filenames):\n",
    "                    self.labels.append(label_df[global_labels].loc[i].values.tolist()[np.random.choice([0,1,2])])\n",
    "                self.labels = torch.tensor(self.labels)\n",
    "            if selec_radio == 'agree_two':\n",
    "                label_df['labels'] = label_df['image_id']\n",
    "                label_df.set_index(\"labels\", inplace = True)\n",
    "                filenames_temp = np.unique(label_df.index.values).tolist()\n",
    "                self.labels = []\n",
    "                filenames = []\n",
    "                for i in filenames_temp:\n",
    "                    a,b = np.unique(label_df.loc[i][global_labels].values, axis = 0, return_counts=True)\n",
    "                    if b >= 2:\n",
    "                        filenames.append(i)\n",
    "                        self.labels.append(a[0])\n",
    "                    self.labels = torch.tensor(self.labels)\n",
    "                    self.full_filenames = [os.path.join(image_loc, i +'.png') for i in filenames]\n",
    "            if selec_radio == 'agree_three':\n",
    "                label_df['labels'] = label_df['image_id']\n",
    "                label_df.set_index(\"labels\", inplace = True)\n",
    "                filenames_temp = np.unique(label_df.index.values).tolist()\n",
    "                self.labels = []\n",
    "                filenames = []\n",
    "                for i in filenames_temp:\n",
    "                    a,b = np.unique(label_df.loc[i][global_labels].values, axis = 0, return_counts=True)\n",
    "                    if b == 3:\n",
    "                        filenames.append(i)\n",
    "                        self.labels.append(a[0])\n",
    "                    self.labels = torch.tensor(self.labels)\n",
    "                    self.full_filenames = [os.path.join(image_loc, i +'.png') for i in filenames]\n",
    "            if selec_radio == 'radio_per_epoch':\n",
    "                label_df['labels'] = label_df['image_id']\n",
    "                label_df.set_index(\"labels\", inplace = True)\n",
    "                filenames = np.unique(label_df.index.values).tolist()\n",
    "                self.labels = []\n",
    "                for i in filenames:\n",
    "                    self.lables.append(label_df.loc[i][global_labels].values[radio_id].tolist())\n",
    "                self.labels = torch.tensor(self.labels)\n",
    "                self.full_filenames = [os.path.join(image_loc, i +'.png') for i in filenames]\n",
    "            if selec_radio == 'all': \n",
    "                label_df['labels'] = label_df['image_id'] +'_'+ label_df['rad_id']\n",
    "                label_df.set_index(\"labels\", inplace = True)\n",
    "                filenames = label_df.index.values.tolist()\n",
    "            \n",
    "                self.full_filenames = [os.path.join(image_loc, i.split('_')[0]+'.png') for i in filenames]\n",
    "                self.labels = []\n",
    "                for i in tqdm(filenames):\n",
    "                    self.labels.append(label_df[global_labels].loc[i].values.tolist())         \n",
    "                self.labels = torch.tensor(self.labels)\n",
    "                \n",
    "        if data_type == 'test':                     \n",
    "            filenames = os.listdir(image_loc)\n",
    "            self.full_filenames = [os.path.join(image_loc, i) for i in filenames]\n",
    "            label_df = pd.read_csv(label_loc)\n",
    "            label_df.set_index(\"image_id\", inplace = True)\n",
    "            self.labels = [label_df[global_labels].loc[filename[:-4]].values for filename in filenames]\n",
    "            \n",
    "        self.transforms = transforms\n",
    "#         self.data_type = data_type\n",
    "    def __len__(self):\n",
    "        return len(self.full_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.full_filenames[idx])\n",
    "        image = self.transforms(image)\n",
    "        \n",
    "        return image, self.labels[idx]\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "44d8dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = { \n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p = 0.4), \n",
    "        transforms.RandomPerspective(distortion_scale=0.3),\n",
    "        transforms.RandomRotation((-30,30)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])        \n",
    "    ])\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5f4e7fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb7139f67664ab1937a9e5aa03d7252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset_rand_one = Vin_big_dataset(image_loc = data_dir['train'],\n",
    "                          label_loc = labels_csv['train'],\n",
    "                          transforms = data_transforms['train'],\n",
    "                          data_type = 'train', selec_radio = 'rand_one')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6a4c981d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11231/2318704125.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                           \u001b[0mlabel_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_csv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                           \u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                           data_type = 'train', selec_radio = 'agree_two')\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_11231/3096789202.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_loc, label_loc, transforms, data_type, selec_radio, radio_id)\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                         \u001b[0mfilenames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "train_dataset_agree_two = Vin_big_dataset(image_loc = data_dir['train'],\n",
    "                          label_loc = labels_csv['train'],\n",
    "                          transforms = data_transforms['train'],\n",
    "                          data_type = 'train', selec_radio = 'agree_two')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb83b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ecf689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11122e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6a5b9259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1024, 1024])\n",
      "tensor([0, 0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset_rand_one:\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1d338006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503c906e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b097c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289f4a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858185a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5df2db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

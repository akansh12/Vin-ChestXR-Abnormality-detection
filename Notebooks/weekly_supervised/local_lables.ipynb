{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c21063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "from torchvision import transforms, models, datasets\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "import cv2\n",
    "import subprocess\n",
    "from collections import OrderedDict\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score, auc\n",
    "from sklearn.metrics import precision_score,recall_score, f1_score\n",
    "import glob\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dbdff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe205ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csv = {'train': \"/storage/home/akansh12/Vin-ChestXR-Abnormality-detection/Notebooks/weekly_supervised/new_image_labels_train.csv\",\n",
    "             'test': \"/scratch/scratch6/akansh12/DeepEXrays/physionet.org/files/vindr-cxr/1.0.0/annotations/image_labels_test.csv\"\n",
    "             }\n",
    "labels_csv_bb = {'train': \"/scratch/scratch6/akansh12/DeepEXrays/physionet.org/files/vindr-cxr/1.0.0/annotations/annotations_train.csv\",\n",
    "             'test': \"/scratch/scratch6/akansh12/DeepEXrays/physionet.org/files/vindr-cxr/1.0.0/annotations/annotations_test.csv\"\n",
    "             }\n",
    "data_dir = {'train': \"/scratch/scratch6/akansh12/DeepEXrays/data/data_256/train/\",\n",
    "           'test': \"/scratch/scratch6/akansh12/DeepEXrays/data/data_256/test/\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3abfecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other diseases', 'No finding']\n",
    "\n",
    "local_labels = ['Aortic enlargement', 'Atelectasis',\n",
    "       'Calcification', 'Cardiomegaly', 'Clavicle fracture', 'Consolidation',\n",
    "       'Edema', 'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration',\n",
    "       'Lung Opacity', 'Lung cavity', 'Lung cyst', 'Mediastinal shift',\n",
    "       'Nodule/Mass', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax',\n",
    "       'Pulmonary fibrosis', 'Rib fracture', 'Other lesion', 'No finding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "901d6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv(labels_csv['train'])\n",
    "test_label = pd.read_csv(labels_csv['test'])\n",
    "train_label_bb = pd.read_csv(labels_csv_bb['train'])\n",
    "test_label_bb = pd.read_csv(labels_csv_bb['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01ce29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vin_big_dataset(Dataset):\n",
    "    def __init__(self, image_loc, label_loc, transforms, data_type, selec_radio, radio_id = None, label_type = None):\n",
    "        if label_type == 'global':\n",
    "            global_labels = ['COPD', 'Lung tumor', 'Pneumonia', 'Tuberculosis', 'Other diseases', 'No finding']\n",
    "        if label_type == 'local':\n",
    "            global_labels = ['Aortic enlargement', 'Atelectasis',\n",
    "       'Calcification', 'Cardiomegaly', 'Clavicle fracture', 'Consolidation',\n",
    "       'Edema', 'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration',\n",
    "       'Lung Opacity', 'Lung cavity', 'Lung cyst', 'Mediastinal shift',\n",
    "       'Nodule/Mass', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax',\n",
    "       'Pulmonary fibrosis', 'Rib fracture', 'Other lesion', 'No finding']\n",
    "        \n",
    "        if data_type == 'train':\n",
    "            label_df = pd.read_csv(label_loc)\n",
    "            if selec_radio == 'rand_one':\n",
    "                label_df['labels'] = label_df['image_id']\n",
    "                label_df.set_index(\"labels\", inplace = True)\n",
    "                filenames = np.unique(label_df.index.values).tolist()\n",
    "                self.full_filenames = [os.path.join(image_loc, i +'.png') for i in filenames]\n",
    "                self.labels = []\n",
    "                for i in (filenames):\n",
    "                    self.labels.append(label_df[global_labels].loc[i].values.tolist()[np.random.choice([0,1,2])])\n",
    "                self.labels = torch.tensor(self.labels)\n",
    "            if selec_radio == 'agree_two':\n",
    "                label_df['labels'] = label_df['image_id']\n",
    "                label_df.set_index(\"labels\", inplace = True)\n",
    "                filenames_temp = np.unique(label_df.index.values).tolist()\n",
    "                self.labels = []\n",
    "                filenames = []\n",
    "                for i in filenames_temp:\n",
    "                    a,b = np.unique(label_df.loc[i][global_labels].values, axis = 0, return_counts=True)\n",
    "                    if b[0] >= 2:\n",
    "                        filenames.append(i)\n",
    "                        self.labels.append(a[0])\n",
    "                self.labels = torch.tensor(self.labels)\n",
    "                self.full_filenames = [os.path.join(image_loc, i +'.png') for i in filenames]\n",
    "            if selec_radio == 'agree_three':\n",
    "                label_df['labels'] = label_df['image_id']\n",
    "                label_df.set_index(\"labels\", inplace = True)\n",
    "                filenames_temp = np.unique(label_df.index.values).tolist()\n",
    "                self.labels = []\n",
    "                filenames = []\n",
    "                for i in filenames_temp:\n",
    "                    a,b = np.unique(label_df.loc[i][global_labels].values, axis = 0, return_counts=True)\n",
    "                    if b[0] == 3:\n",
    "                        filenames.append(i)\n",
    "                        self.labels.append(a[0])\n",
    "                self.labels = torch.tensor(self.labels)\n",
    "                self.full_filenames = [os.path.join(image_loc, i +'.png') for i in filenames]\n",
    "            if selec_radio == 'radio_per_epoch':\n",
    "                label_df['labels'] = label_df['image_id']\n",
    "                label_df.set_index(\"labels\", inplace = True)\n",
    "                filenames = np.unique(label_df.index.values).tolist()\n",
    "                self.labels = []\n",
    "                for i in filenames:\n",
    "                    self.labels.append(label_df.loc[i][global_labels].values[radio_id].tolist())\n",
    "                self.labels = torch.tensor(self.labels)\n",
    "                self.full_filenames = [os.path.join(image_loc, i +'.png') for i in filenames]\n",
    "            if selec_radio == 'all': \n",
    "#                 label_df['labels'] = label_df['image_id'] +'_'+ label_df['rad_id']\n",
    "                label_df.set_index(\"image_id\", inplace = True)\n",
    "                filenames = label_df.index.values.tolist()\n",
    "            \n",
    "                self.full_filenames = [os.path.join(image_loc,i+'.png') for i in filenames]\n",
    "                self.labels = []\n",
    "                for i in tqdm(filenames):\n",
    "                    self.labels.append(label_df[global_labels].loc[i].values.tolist())         \n",
    "                self.labels = torch.tensor(self.labels)\n",
    "                \n",
    "        if data_type == 'test':                     \n",
    "            filenames = os.listdir(image_loc)\n",
    "            self.full_filenames = [os.path.join(image_loc, i) for i in filenames]\n",
    "            label_df = pd.read_csv(label_loc)\n",
    "            label_df.set_index(\"image_id\", inplace = True)\n",
    "            self.labels = [label_df[global_labels].loc[filename[:-4]].values for filename in filenames]\n",
    "            \n",
    "        self.transforms = transforms\n",
    "        self.norm_transform = A.Normalize()\n",
    "#         self.data_type = data_type\n",
    "    def __len__(self):\n",
    "        return len(self.full_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.full_filenames[idx])\n",
    "        augmented = self.transforms(image=np.array(image))\n",
    "        img = augmented['image']\n",
    "        img = self.norm_transform(image=img)[\"image\"]\n",
    "        \n",
    "        return torch.tensor(img), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "687a8e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose([\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.VerticalFlip(p = 0.2),\n",
    "    A.RandomRotate90(p=0.1),\n",
    "    A.Rotate((-30,30), p = 0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=10, p=0.3),\n",
    "    A.CLAHE(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=5)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.Rotate(0, p = 1)\n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96de3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = { \n",
    "#     \"train\": transforms.Compose([\n",
    "#         transforms.RandomHorizontalFlip(p = 0.5), \n",
    "#         transforms.RandomPerspective(distortion_scale=0.3),\n",
    "#         transforms.RandomRotation((-30,30)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "    \n",
    "#     \"test\": transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])        \n",
    "#     ])\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01ae1e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5115675fd0c742ceaaf02814d767ffc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = Vin_big_dataset(image_loc = data_dir['train'],\n",
    "                          label_loc = labels_csv['train'],\n",
    "                          transforms = train_transforms,\n",
    "                          data_type = 'train', selec_radio = 'all', label_type = 'local')\n",
    "\n",
    "test_data = Vin_big_dataset(image_loc = data_dir['test'],\n",
    "                          label_loc = labels_csv['test'],\n",
    "                          transforms = test_transforms,\n",
    "                          data_type = 'test', selec_radio = None, label_type = 'local')\n",
    "\n",
    "trainloader = DataLoader(train_data,batch_size = 4,shuffle = False)\n",
    "testloader = DataLoader(test_data,batch_size = 8,shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e94880b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256, 256, 3])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "for x, y in trainloader:\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4982fcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model('efficientnet_b6', pretrained=False)\n",
    "model.load_state_dict(torch.load(\"/storage/home/akansh12/Vin-ChestXR-Abnormality-detection/model/tf_efficientnet_b6_aa-80ba17e4.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a99daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(OrderedDict([\n",
    "    ('fcl1', nn.Linear(2304,23)),\n",
    "    ('out', nn.Sigmoid()),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b1bf16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, lr_scheduler,\n",
    "                    dataloader, epoch, criterion, device):\n",
    "    \n",
    "    print(\"Start Train ...\")\n",
    "    model.train()\n",
    "\n",
    "    losses_train = []\n",
    "    model_train_result = []\n",
    "    train_target = []\n",
    "\n",
    "\n",
    "    for data, targets in tqdm(dataloader):\n",
    "        data = data.permute(0,3,1,2).to(device).float()\n",
    "        targets = targets.to(device).type(torch.float)\n",
    "\n",
    "\n",
    "        outputs = model(data)\n",
    "        model_train_result.extend(outputs.detach().cpu().numpy().tolist())\n",
    "        train_target.extend(targets.cpu().numpy())\n",
    "\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        losses_train.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    F1_train = f1_score(train_target, (np.array(model_train_result) > 0.5), average=None)\n",
    "\n",
    "        \n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    lr = lr_scheduler.get_last_lr()[0]\n",
    "    print(\"Epoch [%d]\" % (epoch),\n",
    "          \"Mean loss on train:\", np.array(losses_train).mean(), \n",
    "          \"F1 score:\",np.array(F1_train),\n",
    "          \"Learning Rate:\", lr)\n",
    "\n",
    "    \n",
    "    return np.array(losses_train).mean(), np.array(F1_train), lr\n",
    "\n",
    "\n",
    "def val_epoch(model, dataloader, epoch, criterion, device):\n",
    "    \n",
    "    print(\"Start Validation ...\")\n",
    "    model.eval()\n",
    "    \n",
    "    model_val_result = []\n",
    "    val_target = []\n",
    "    losses_val = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in tqdm(dataloader):\n",
    "\n",
    "            data = data.permute(0,3,1,2).to(device).float()\n",
    "            targets = targets.to(device).type(torch.float)\n",
    "\n",
    "            outputs = model(data)\n",
    "            \n",
    "            #loss\n",
    "            loss = criterion(outputs, targets)\n",
    "            losses_val.append(loss.item())\n",
    "\n",
    "            \n",
    "            model_val_result.extend(outputs.detach().cpu().numpy().tolist())\n",
    "            val_target.extend(targets.cpu().numpy())\n",
    "            \n",
    "        F1_val = f1_score(val_target, (np.array(model_val_result) > 0.5), average=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(\"Epoch:  \" + str(epoch) + \" F1 valid Score:\", np.array(F1_val), \n",
    "              \"Mean Loss\", np.array(losses_val).mean())\n",
    "        \n",
    "    return np.array(losses_val).mean(), np.array(F1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3721a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b40d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "num_epochs = 50\n",
    "optimizer = optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr = 0.1, steps_per_epoch=1, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c7fe589",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss(reduction= 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd97107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Validation ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd1e2faf17849f0ad66fd5a565b3afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3257/1057122821.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#     train_loss, train_f1, lr = train_one_epoch(model, optimizer, lr_scheduler,trainloader, epoch, criterion, device = device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3257/1403534838.py\u001b[0m in \u001b[0;36mval_epoch\u001b[0;34m(model, dataloader, epoch, criterion, device)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m#loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/timm/models/efficientnet_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Point-wise expansion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_pw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weights_dir = \"/scratch/scratch6/akansh12/DeepEXrays/local_label/efficient-net/\"\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "train_f1_history = []\n",
    "val_f1_history = []\n",
    "lr_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "#     train_loss, train_f1, lr = train_one_epoch(model, optimizer, lr_scheduler,trainloader, epoch, criterion, device = device)\n",
    "\n",
    "    val_loss, val_f1 = val_epoch(model, testloader, epoch, criterion, device = device)\n",
    "\n",
    "\n",
    "    # train history\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_f1_history.append(train_f1)\n",
    "    lr_history.append(lr)\n",
    "\n",
    "    #val history\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_f1_history.append(val_f1)\n",
    "\n",
    "    # save best weights\n",
    "    best_loss = min(val_loss_history)\n",
    "    if val_loss <= best_loss:\n",
    "        print('saving model')\n",
    "        torch.save({'state_dict': model.state_dict()},\n",
    "                    os.path.join(weights_dir, f\"{val_loss:0.6f}_.pth\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6e4eac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6605295968937377"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c68fc2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6605295968937377]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3ace706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2967,  0.4328,  0.6531],\n",
       "          [ 0.2967,  0.4328,  0.6531],\n",
       "          [ 0.2967,  0.4328,  0.6531],\n",
       "          ...,\n",
       "          [ 0.4337,  0.5728,  0.7925],\n",
       "          [ 1.2385,  1.3957,  1.6117],\n",
       "          [ 0.7933,  0.9405,  1.1585]],\n",
       "\n",
       "         [[ 0.2282,  0.3627,  0.5834],\n",
       "          [ 0.2624,  0.3978,  0.6182],\n",
       "          [ 0.2624,  0.3978,  0.6182],\n",
       "          ...,\n",
       "          [ 0.8447,  0.9930,  1.2108],\n",
       "          [ 0.6734,  0.8179,  1.0365],\n",
       "          [-0.1486, -0.0224,  0.1999]],\n",
       "\n",
       "         [[ 0.1768,  0.3102,  0.5311],\n",
       "          [ 0.2282,  0.3627,  0.5834],\n",
       "          [ 0.2111,  0.3452,  0.5659],\n",
       "          ...,\n",
       "          [ 0.2967,  0.4328,  0.6531],\n",
       "          [-0.2513, -0.1275,  0.0953],\n",
       "          [-0.7308, -0.6176, -0.3927]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.6838,  1.8508,  2.0648],\n",
       "          [ 1.6838,  1.8508,  2.0648],\n",
       "          [ 1.6838,  1.8508,  2.0648],\n",
       "          ...,\n",
       "          [ 1.0159,  1.1681,  1.3851],\n",
       "          [ 0.8789,  1.0280,  1.2457],\n",
       "          [ 0.6221,  0.7654,  0.9842]],\n",
       "\n",
       "         [[ 1.6838,  1.8508,  2.0648],\n",
       "          [ 1.6838,  1.8508,  2.0648],\n",
       "          [ 1.6838,  1.8508,  2.0648],\n",
       "          ...,\n",
       "          [ 1.0844,  1.2381,  1.4548],\n",
       "          [ 1.0331,  1.1856,  1.4025],\n",
       "          [ 0.8276,  0.9755,  1.1934]],\n",
       "\n",
       "         [[ 1.6667,  1.8333,  2.0474],\n",
       "          [ 1.6838,  1.8508,  2.0648],\n",
       "          [ 1.6838,  1.8508,  2.0648],\n",
       "          ...,\n",
       "          [ 1.0502,  1.2031,  1.4200],\n",
       "          [ 1.0159,  1.1681,  1.3851],\n",
       "          [ 0.8789,  1.0280,  1.2457]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1804,  2.3585,  2.5703],\n",
       "          [ 2.1804,  2.3585,  2.5703],\n",
       "          [ 2.1804,  2.3585,  2.5703],\n",
       "          ...,\n",
       "          [ 0.9646,  1.1155,  1.3328],\n",
       "          [ 0.8276,  0.9755,  1.1934],\n",
       "          [ 0.6906,  0.8354,  1.0539]],\n",
       "\n",
       "         [[ 2.1804,  2.3585,  2.5703],\n",
       "          [ 2.0948,  2.2710,  2.4831],\n",
       "          [ 2.1804,  2.3585,  2.5703],\n",
       "          ...,\n",
       "          [ 1.0502,  1.2031,  1.4200],\n",
       "          [ 0.9646,  1.1155,  1.3328],\n",
       "          [ 0.8961,  1.0455,  1.2631]],\n",
       "\n",
       "         [[ 2.0948,  2.2710,  2.4831],\n",
       "          [ 2.1804,  2.3585,  2.5703],\n",
       "          [ 2.1804,  2.3585,  2.5703],\n",
       "          ...,\n",
       "          [ 1.1529,  1.3081,  1.5245],\n",
       "          [ 1.0159,  1.1681,  1.3851],\n",
       "          [ 0.9303,  1.0805,  1.2980]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.2513, -0.1275,  0.0953],\n",
       "          [-0.1486, -0.0224,  0.1999],\n",
       "          [ 0.1083,  0.2402,  0.4614],\n",
       "          ...,\n",
       "          [ 1.5297,  1.6933,  1.9080],\n",
       "          [ 1.6324,  1.7983,  2.0125],\n",
       "          [ 1.8037,  1.9734,  2.1868]],\n",
       "\n",
       "         [[-0.2171, -0.0924,  0.1302],\n",
       "          [-0.1143,  0.0126,  0.2348],\n",
       "          [ 0.2967,  0.4328,  0.6531],\n",
       "          ...,\n",
       "          [ 1.5810,  1.7458,  1.9603],\n",
       "          [ 1.6667,  1.8333,  2.0474],\n",
       "          [ 1.7865,  1.9559,  2.1694]],\n",
       "\n",
       "         [[-0.1828, -0.0574,  0.1651],\n",
       "          [ 0.1083,  0.2402,  0.4614],\n",
       "          [ 0.4337,  0.5728,  0.7925],\n",
       "          ...,\n",
       "          [ 1.6495,  1.8158,  2.0300],\n",
       "          [ 1.7523,  1.9209,  2.1346],\n",
       "          [ 1.7865,  1.9559,  2.1694]]],\n",
       "\n",
       "\n",
       "        [[[-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          ...,\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044]],\n",
       "\n",
       "         [[-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          ...,\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044]],\n",
       "\n",
       "         [[-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          ...,\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.1179, -2.0357, -1.8044],\n",
       "          [-1.8439, -1.7556, -1.5256],\n",
       "          [-1.0390, -0.9328, -0.7064],\n",
       "          ...,\n",
       "          [-0.2856, -0.1625,  0.0605],\n",
       "          [-1.6727, -1.5805, -1.3513],\n",
       "          [-2.1179, -2.0357, -1.8044]],\n",
       "\n",
       "         [[-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          [-1.8610, -1.7731, -1.5430],\n",
       "          ...,\n",
       "          [-1.6727, -1.5805, -1.3513],\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044]],\n",
       "\n",
       "         [[-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          ...,\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044],\n",
       "          [-2.1179, -2.0357, -1.8044]]],\n",
       "\n",
       "\n",
       "        [[[-1.6727, -1.5805, -1.3513],\n",
       "          [-1.6898, -1.5980, -1.3687],\n",
       "          [-1.7240, -1.6331, -1.4036],\n",
       "          ...,\n",
       "          [-1.8439, -1.7556, -1.5256],\n",
       "          [-1.8610, -1.7731, -1.5430],\n",
       "          [-1.8610, -1.7731, -1.5430]],\n",
       "\n",
       "         [[-1.6727, -1.5805, -1.3513],\n",
       "          [-1.6898, -1.5980, -1.3687],\n",
       "          [-1.7069, -1.6155, -1.3861],\n",
       "          ...,\n",
       "          [-1.8610, -1.7731, -1.5430],\n",
       "          [-1.8610, -1.7731, -1.5430],\n",
       "          [-1.8610, -1.7731, -1.5430]],\n",
       "\n",
       "         [[-1.6727, -1.5805, -1.3513],\n",
       "          [-1.6898, -1.5980, -1.3687],\n",
       "          [-1.7069, -1.6155, -1.3861],\n",
       "          ...,\n",
       "          [-1.8610, -1.7731, -1.5430],\n",
       "          [-1.8610, -1.7731, -1.5430],\n",
       "          [-1.8610, -1.7731, -1.5430]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.9988,  1.1506,  1.3677],\n",
       "          [ 0.9988,  1.1506,  1.3677],\n",
       "          [ 0.9646,  1.1155,  1.3328],\n",
       "          ...,\n",
       "          [-1.8610, -1.7731, -1.5430],\n",
       "          [-1.8610, -1.7731, -1.5430],\n",
       "          [-1.8610, -1.7731, -1.5430]],\n",
       "\n",
       "         [[ 0.9646,  1.1155,  1.3328],\n",
       "          [ 0.9474,  1.0980,  1.3154],\n",
       "          [ 0.9474,  1.0980,  1.3154],\n",
       "          ...,\n",
       "          [-1.8610, -1.7731, -1.5430],\n",
       "          [-1.8610, -1.7731, -1.5430],\n",
       "          [-1.8610, -1.7731, -1.5430]],\n",
       "\n",
       "         [[ 0.9474,  1.0980,  1.3154],\n",
       "          [ 0.9303,  1.0805,  1.2980],\n",
       "          [ 0.9132,  1.0630,  1.2805],\n",
       "          ...,\n",
       "          [-1.8268, -1.7381, -1.5081],\n",
       "          [-1.8439, -1.7556, -1.5256],\n",
       "          [-1.8268, -1.7381, -1.5081]]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0686b9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d361d5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace25b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684e2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
